{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\danilo marinduque\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "2018-04-19 14:38:01,427 : INFO : 'pattern' package not found; tag filters are not available for English\n",
      "c:\\users\\danilo marinduque\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "logging.root.handlers = []  # Jupyter messes up logging so needs a reset\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "from smart_open import smart_open\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "import gensim\n",
    "import nltk\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import linear_model\n",
    "from nltk.corpus import stopwords\n",
    "import gensim\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning, module='gensim')\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "434630"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/Shuffle_Data.csv')\n",
    "df = df.dropna()\n",
    "df['content'].apply(lambda x: len(x.split(' '))).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df['content'], df['tag']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train own word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-04-19 14:38:02,714 : INFO : read 60 cases\n",
      "2018-04-19 14:38:02,749 : INFO : read 240 cases\n",
      "2018-04-19 14:38:02,753 : INFO : read 90 cases\n",
      "2018-04-19 14:38:02,795 : INFO : read 170 cases\n",
      "2018-04-19 14:38:02,847 : INFO : read 150 cases\n",
      "2018-04-19 14:38:02,862 : INFO : read 140 cases\n",
      "2018-04-19 14:38:02,865 : INFO : read 0 cases\n",
      "2018-04-19 14:38:02,876 : INFO : read 100 cases\n",
      "2018-04-19 14:38:02,933 : INFO : read 70 cases\n",
      "2018-04-19 14:38:02,943 : INFO : read 40 cases\n",
      "2018-04-19 14:38:02,952 : INFO : read 190 cases\n",
      "2018-04-19 14:38:03,016 : INFO : read 230 cases\n",
      "2018-04-19 14:38:03,023 : INFO : read 80 cases\n",
      "2018-04-19 14:38:03,038 : INFO : read 110 cases\n",
      "2018-04-19 14:38:03,134 : INFO : read 50 cases\n",
      "2018-04-19 14:38:03,184 : INFO : read 160 cases\n",
      "2018-04-19 14:38:03,239 : INFO : read 130 cases\n",
      "2018-04-19 14:38:03,260 : INFO : read 210 cases\n",
      "2018-04-19 14:38:03,276 : INFO : read 20 cases\n",
      "2018-04-19 14:38:03,313 : INFO : Done reading data file\n"
     ]
    }
   ],
   "source": [
    "def read(data):\n",
    "    for i,line in data.iteritems():\n",
    "        if(i%10==0):\n",
    "            logging.info(\"read {0} cases\".format(i))\n",
    "        yield gensim.utils.simple_preprocess (line)\n",
    "\n",
    "documents = list(read(X_train.to_frame()['content']))\n",
    "logging.info (\"Done reading data file\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-04-19 14:38:03,325 : INFO : collecting all words and their counts\n",
      "2018-04-19 14:38:03,328 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2018-04-19 14:38:03,395 : INFO : collected 15520 word types from a corpus of 318322 raw words and 202 sentences\n",
      "2018-04-19 14:38:03,397 : INFO : Loading a fresh vocabulary\n",
      "2018-04-19 14:38:03,428 : INFO : min_count=5 retains 4905 unique words (31% of original 15520, drops 10615)\n",
      "2018-04-19 14:38:03,429 : INFO : min_count=5 leaves 300680 word corpus (94% of original 318322, drops 17642)\n",
      "2018-04-19 14:38:03,450 : INFO : deleting the raw counts dictionary of 15520 items\n",
      "2018-04-19 14:38:03,454 : INFO : sample=0.001 downsamples 47 most-common words\n",
      "2018-04-19 14:38:03,456 : INFO : downsampling leaves estimated 217722 word corpus (72.4% of prior 300680)\n",
      "2018-04-19 14:38:03,482 : INFO : estimated required memory for 4905 words and 100 dimensions: 6376500 bytes\n",
      "2018-04-19 14:38:03,483 : INFO : resetting layer weights\n",
      "2018-04-19 14:38:03,560 : INFO : training model with 10 workers on 4905 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2018-04-19 14:38:03,742 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2018-04-19 14:38:03,753 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2018-04-19 14:38:03,755 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-04-19 14:38:03,771 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-04-19 14:38:03,778 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-04-19 14:38:03,783 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-04-19 14:38:03,791 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-19 14:38:03,796 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-19 14:38:03,807 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-19 14:38:03,809 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-19 14:38:03,811 : INFO : EPOCH - 1 : training on 318322 raw words (217794 effective words) took 0.2s, 912976 effective words/s\n",
      "2018-04-19 14:38:03,968 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2018-04-19 14:38:03,980 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2018-04-19 14:38:03,986 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-04-19 14:38:03,988 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-04-19 14:38:03,992 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-04-19 14:38:04,023 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-04-19 14:38:04,028 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-19 14:38:04,030 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-19 14:38:04,032 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-19 14:38:04,034 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-19 14:38:04,036 : INFO : EPOCH - 2 : training on 318322 raw words (217334 effective words) took 0.2s, 989950 effective words/s\n",
      "2018-04-19 14:38:04,232 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2018-04-19 14:38:04,238 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2018-04-19 14:38:04,243 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-04-19 14:38:04,249 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-04-19 14:38:04,252 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-04-19 14:38:04,254 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-04-19 14:38:04,256 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-19 14:38:04,269 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-19 14:38:04,276 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-19 14:38:04,290 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-19 14:38:04,292 : INFO : EPOCH - 3 : training on 318322 raw words (217664 effective words) took 0.2s, 894541 effective words/s\n",
      "2018-04-19 14:38:04,519 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2018-04-19 14:38:04,522 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2018-04-19 14:38:04,527 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-04-19 14:38:04,532 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-04-19 14:38:04,535 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-04-19 14:38:04,539 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-04-19 14:38:04,541 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-19 14:38:04,554 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-19 14:38:04,558 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-19 14:38:04,563 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-19 14:38:04,565 : INFO : EPOCH - 4 : training on 318322 raw words (217739 effective words) took 0.3s, 841004 effective words/s\n",
      "2018-04-19 14:38:04,794 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2018-04-19 14:38:04,797 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2018-04-19 14:38:04,813 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-04-19 14:38:04,821 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-04-19 14:38:04,826 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-04-19 14:38:04,831 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-04-19 14:38:04,838 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-19 14:38:04,841 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-19 14:38:04,842 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-19 14:38:04,843 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-19 14:38:04,844 : INFO : EPOCH - 5 : training on 318322 raw words (217833 effective words) took 0.3s, 825586 effective words/s\n",
      "2018-04-19 14:38:04,844 : INFO : training on a 1591610 raw words (1088364 effective words) took 1.3s, 848647 effective words/s\n",
      "2018-04-19 14:38:04,846 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2018-04-19 14:38:04,847 : INFO : training model with 10 workers on 4905 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2018-04-19 14:38:05,058 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2018-04-19 14:38:05,073 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2018-04-19 14:38:05,085 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-04-19 14:38:05,087 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-04-19 14:38:05,092 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-04-19 14:38:05,096 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-04-19 14:38:05,102 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-19 14:38:05,107 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-19 14:38:05,108 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-19 14:38:05,111 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-19 14:38:05,113 : INFO : EPOCH - 1 : training on 318322 raw words (217927 effective words) took 0.2s, 883978 effective words/s\n",
      "2018-04-19 14:38:05,299 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2018-04-19 14:38:05,309 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2018-04-19 14:38:05,322 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-04-19 14:38:05,333 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-04-19 14:38:05,337 : INFO : worker thread finished; awaiting finish of 5 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-04-19 14:38:05,340 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-04-19 14:38:05,340 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-19 14:38:05,342 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-19 14:38:05,345 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-19 14:38:05,348 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-19 14:38:05,349 : INFO : EPOCH - 2 : training on 318322 raw words (217631 effective words) took 0.2s, 949243 effective words/s\n",
      "2018-04-19 14:38:05,525 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2018-04-19 14:38:05,534 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2018-04-19 14:38:05,548 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-04-19 14:38:05,554 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-04-19 14:38:05,560 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-04-19 14:38:05,565 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-04-19 14:38:05,572 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-19 14:38:05,576 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-19 14:38:05,582 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-19 14:38:05,587 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-19 14:38:05,589 : INFO : EPOCH - 3 : training on 318322 raw words (217724 effective words) took 0.2s, 939620 effective words/s\n",
      "2018-04-19 14:38:05,772 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2018-04-19 14:38:05,799 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2018-04-19 14:38:05,812 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-04-19 14:38:05,816 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-04-19 14:38:05,819 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-04-19 14:38:05,821 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-04-19 14:38:05,823 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-19 14:38:05,825 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-19 14:38:05,826 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-19 14:38:05,833 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-19 14:38:05,835 : INFO : EPOCH - 4 : training on 318322 raw words (217591 effective words) took 0.2s, 903140 effective words/s\n",
      "2018-04-19 14:38:06,062 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2018-04-19 14:38:06,083 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2018-04-19 14:38:06,096 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-04-19 14:38:06,099 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-04-19 14:38:06,104 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-04-19 14:38:06,111 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-04-19 14:38:06,122 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-19 14:38:06,137 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-19 14:38:06,143 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-19 14:38:06,149 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-19 14:38:06,154 : INFO : EPOCH - 5 : training on 318322 raw words (217662 effective words) took 0.3s, 741754 effective words/s\n",
      "2018-04-19 14:38:06,432 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2018-04-19 14:38:06,448 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2018-04-19 14:38:06,465 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-04-19 14:38:06,469 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-04-19 14:38:06,470 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-04-19 14:38:06,472 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-04-19 14:38:06,473 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-19 14:38:06,474 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-19 14:38:06,475 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-19 14:38:06,492 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-19 14:38:06,493 : INFO : EPOCH - 6 : training on 318322 raw words (217562 effective words) took 0.3s, 688530 effective words/s\n",
      "2018-04-19 14:38:06,660 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2018-04-19 14:38:06,683 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2018-04-19 14:38:06,698 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-04-19 14:38:06,701 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-04-19 14:38:06,708 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-04-19 14:38:06,709 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-04-19 14:38:06,711 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-19 14:38:06,712 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-19 14:38:06,713 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-19 14:38:06,714 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-19 14:38:06,715 : INFO : EPOCH - 7 : training on 318322 raw words (217651 effective words) took 0.2s, 1008420 effective words/s\n",
      "2018-04-19 14:38:06,891 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2018-04-19 14:38:06,895 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2018-04-19 14:38:06,898 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-04-19 14:38:06,900 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-04-19 14:38:06,902 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-04-19 14:38:06,904 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-04-19 14:38:06,906 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-19 14:38:06,908 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-19 14:38:06,910 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-19 14:38:06,913 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-19 14:38:06,915 : INFO : EPOCH - 8 : training on 318322 raw words (217512 effective words) took 0.2s, 1168045 effective words/s\n",
      "2018-04-19 14:38:07,067 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2018-04-19 14:38:07,081 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2018-04-19 14:38:07,088 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-04-19 14:38:07,090 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-04-19 14:38:07,092 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-04-19 14:38:07,094 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-04-19 14:38:07,098 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-19 14:38:07,101 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-19 14:38:07,107 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-19 14:38:07,109 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-19 14:38:07,110 : INFO : EPOCH - 9 : training on 318322 raw words (217692 effective words) took 0.2s, 1151890 effective words/s\n",
      "2018-04-19 14:38:07,257 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2018-04-19 14:38:07,267 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2018-04-19 14:38:07,278 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-04-19 14:38:07,288 : INFO : worker thread finished; awaiting finish of 6 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-04-19 14:38:07,292 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-04-19 14:38:07,295 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-04-19 14:38:07,297 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-19 14:38:07,302 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-19 14:38:07,313 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-19 14:38:07,315 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-19 14:38:07,316 : INFO : EPOCH - 10 : training on 318322 raw words (217602 effective words) took 0.2s, 1085544 effective words/s\n",
      "2018-04-19 14:38:07,475 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2018-04-19 14:38:07,492 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2018-04-19 14:38:07,519 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-04-19 14:38:07,529 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-04-19 14:38:07,530 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-04-19 14:38:07,532 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-04-19 14:38:07,537 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-19 14:38:07,540 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-19 14:38:07,542 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-19 14:38:07,544 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-19 14:38:07,546 : INFO : EPOCH - 11 : training on 318322 raw words (217807 effective words) took 0.2s, 974674 effective words/s\n",
      "2018-04-19 14:38:07,738 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2018-04-19 14:38:07,758 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2018-04-19 14:38:07,764 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-04-19 14:38:07,769 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-04-19 14:38:07,775 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-04-19 14:38:07,783 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-04-19 14:38:07,793 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-19 14:38:07,800 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-19 14:38:07,802 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-19 14:38:07,804 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-19 14:38:07,806 : INFO : EPOCH - 12 : training on 318322 raw words (217818 effective words) took 0.2s, 878048 effective words/s\n",
      "2018-04-19 14:38:07,979 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2018-04-19 14:38:07,990 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2018-04-19 14:38:08,008 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-04-19 14:38:08,012 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-04-19 14:38:08,018 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-04-19 14:38:08,020 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-04-19 14:38:08,022 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-19 14:38:08,024 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-19 14:38:08,026 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-19 14:38:08,033 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-19 14:38:08,036 : INFO : EPOCH - 13 : training on 318322 raw words (217662 effective words) took 0.2s, 1012338 effective words/s\n",
      "2018-04-19 14:38:08,187 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2018-04-19 14:38:08,199 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2018-04-19 14:38:08,208 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-04-19 14:38:08,219 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-04-19 14:38:08,224 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-04-19 14:38:08,226 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-04-19 14:38:08,230 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-19 14:38:08,235 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-19 14:38:08,238 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-19 14:38:08,240 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-19 14:38:08,242 : INFO : EPOCH - 14 : training on 318322 raw words (217913 effective words) took 0.2s, 1088306 effective words/s\n",
      "2018-04-19 14:38:08,400 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2018-04-19 14:38:08,413 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2018-04-19 14:38:08,423 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-04-19 14:38:08,431 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-04-19 14:38:08,435 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-04-19 14:38:08,439 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-04-19 14:38:08,441 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-19 14:38:08,453 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-19 14:38:08,455 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-19 14:38:08,457 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-19 14:38:08,459 : INFO : EPOCH - 15 : training on 318322 raw words (217830 effective words) took 0.2s, 1075826 effective words/s\n",
      "2018-04-19 14:38:08,611 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2018-04-19 14:38:08,624 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2018-04-19 14:38:08,630 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-04-19 14:38:08,635 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-04-19 14:38:08,642 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-04-19 14:38:08,650 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-04-19 14:38:08,652 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-19 14:38:08,655 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-19 14:38:08,656 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-19 14:38:08,660 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-19 14:38:08,662 : INFO : EPOCH - 16 : training on 318322 raw words (217942 effective words) took 0.2s, 1108155 effective words/s\n",
      "2018-04-19 14:38:08,810 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2018-04-19 14:38:08,821 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2018-04-19 14:38:08,829 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-04-19 14:38:08,834 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-04-19 14:38:08,849 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-04-19 14:38:08,854 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-04-19 14:38:08,857 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-19 14:38:08,859 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-19 14:38:08,860 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-19 14:38:08,866 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-19 14:38:08,869 : INFO : EPOCH - 17 : training on 318322 raw words (217528 effective words) took 0.2s, 1086702 effective words/s\n",
      "2018-04-19 14:38:09,064 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2018-04-19 14:38:09,072 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2018-04-19 14:38:09,081 : INFO : worker thread finished; awaiting finish of 7 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-04-19 14:38:09,085 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-04-19 14:38:09,092 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-04-19 14:38:09,093 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-04-19 14:38:09,095 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-19 14:38:09,099 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-19 14:38:09,105 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-19 14:38:09,114 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-19 14:38:09,118 : INFO : EPOCH - 18 : training on 318322 raw words (217576 effective words) took 0.2s, 904875 effective words/s\n",
      "2018-04-19 14:38:09,314 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2018-04-19 14:38:09,332 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2018-04-19 14:38:09,342 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-04-19 14:38:09,349 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-04-19 14:38:09,353 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-04-19 14:38:09,355 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-04-19 14:38:09,358 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-19 14:38:09,360 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-19 14:38:09,361 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-19 14:38:09,371 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-19 14:38:09,372 : INFO : EPOCH - 19 : training on 318322 raw words (217721 effective words) took 0.2s, 901048 effective words/s\n",
      "2018-04-19 14:38:09,529 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2018-04-19 14:38:09,538 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2018-04-19 14:38:09,545 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-04-19 14:38:09,547 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-04-19 14:38:09,554 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-04-19 14:38:09,556 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-04-19 14:38:09,561 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-04-19 14:38:09,572 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-19 14:38:09,574 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-19 14:38:09,577 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-19 14:38:09,578 : INFO : EPOCH - 20 : training on 318322 raw words (217618 effective words) took 0.2s, 1106668 effective words/s\n",
      "2018-04-19 14:38:09,579 : INFO : training on a 6366440 raw words (4353969 effective words) took 4.7s, 920285 effective words/s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4353969, 6366440)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = gensim.models.Word2Vec (documents, workers=10)\n",
    "model.train(documents,total_examples=len(documents),epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-04-19 14:38:09,592 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('evident', 0.8730087280273438),\n",
       " ('premeditation', 0.8530261516571045),\n",
       " ('cruelty', 0.7841089963912964),\n",
       " ('qualifying', 0.7767015099525452),\n",
       " ('conspiracy', 0.7738387584686279),\n",
       " ('abuse', 0.754420280456543),\n",
       " ('reasonable', 0.7497912049293518),\n",
       " ('strength', 0.7454909086227417),\n",
       " ('aggravating', 0.7349112629890442),\n",
       " ('superior', 0.7344695329666138)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word1 = \"treachery\"\n",
    "model.wv.most_similar (positive=word1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_averaging(wv, words):\n",
    "    all_words, mean = set(), []\n",
    "    \n",
    "    for word in words:\n",
    "        if isinstance(word, np.ndarray):\n",
    "            mean.append(word)\n",
    "        elif word in model.wv.vocab:\n",
    "            mean.append(model.wv.vectors[model.wv.vocab[word].index])\n",
    "            all_words.add(model.wv.vocab[word].index)\n",
    "\n",
    "    if not mean:\n",
    "        logging.warning(\"cannot compute similarity with no input %s\", words)\n",
    "        return np.zeros(wv.trainables.layer1_size,)\n",
    "\n",
    "    mean = gensim.matutils.unitvec(np.array(mean).mean(axis=0)).astype(np.float32)\n",
    "    return mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  word_averaging_list(wv, text_list):\n",
    "    return np.vstack([word_averaging(wv, review) for review in text_list ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def w2v_tokenize_text(text):\n",
    "    tokens = []\n",
    "    for sent in nltk.sent_tokenize(text, language='english'):\n",
    "        for word in nltk.word_tokenize(sent, language='english'):\n",
    "            if len(word) < 2:\n",
    "                continue\n",
    "            tokens.append(word)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tokenized = X_test.to_frame().apply(lambda r: w2v_tokenize_text(r['content']), axis=1).values\n",
    "train_tokenized = X_train.to_frame().apply(lambda r: w2v_tokenize_text(r['content']), axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_word_average = word_averaging_list(model,train_tokenized)\n",
    "X_test_word_average = word_averaging_list(model,test_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using SVM with 5 cross validation : 68.3%\n"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(LinearSVC(C=4)) # C=1.0, max_iter=1000\n",
    "score = cross_val_score(clf, X_train_word_average,  y_train.to_frame()['tag'], cv=5)\n",
    "cv = np.mean(score)\n",
    "print (\"Accuracy using SVM with 5 cross validation : {}%\".format(round(cv*100,2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=LinearSVC(C=4, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0),\n",
       "          n_jobs=1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train_word_average, y_train.to_frame()['tag'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8431372549019608\n"
     ]
    }
   ],
   "source": [
    "pred = clf.predict(X_test_word_average)\n",
    "accuracy = clf.score(X_test_word_average,y_test.to_frame().tag)\n",
    "print (accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_testArray = X_test.values\n",
    "y_testArray = y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[14  3  0]\n",
      " [ 2 19  0]\n",
      " [ 1  2 10]]\n"
     ]
    }
   ],
   "source": [
    "# row : actual :: column : predicted \n",
    "cf = confusion_matrix(y_testArray,pred)\n",
    "print (cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  total classes\n",
    "from __future__ import division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 3\n",
    "classes = {0:'Homicide', 1:'Parricide', 2:'Murder'}\n",
    "category = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrueP = []\n",
    "FalseN = []\n",
    "FalseP = []\n",
    "TrueN = []\n",
    "\n",
    "pre = 0\n",
    "rec = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Homicide\n",
      "14 3 3 31\n",
      "Precision:  0.8235294117647058\n",
      "Recall:  0.8235294117647058\n",
      "\n",
      "\n",
      "Parricide\n",
      "19 2 5 25\n",
      "Precision:  0.7916666666666666\n",
      "Recall:  0.9047619047619048\n",
      "\n",
      "\n",
      "Murder\n",
      "10 3 0 38\n",
      "Precision:  1.0\n",
      "Recall:  0.7692307692307693\n",
      "\n",
      "\n",
      "pre:  0.8717320261437909\n",
      "rec: 0.8325073619191267\n"
     ]
    }
   ],
   "source": [
    "for category in range(total):\n",
    "    TP = FN = FP = TN = 0 \n",
    "    for i in range(total):\n",
    "        for j in range(total):\n",
    "            if i==category and j==category:\n",
    "                TP += cf[i][j]\n",
    "            elif i==category and j!=category:\n",
    "                FN += cf[i][j]\n",
    "            elif i!=category and j==category:\n",
    "                FP += cf[i][j]\n",
    "            else:\n",
    "                TN += cf[i][j]\n",
    "    print (classes.get(category))\n",
    "    print (TP, FN, FP, TN)\n",
    "    print (\"Precision: \" , TP/(TP+FP))\n",
    "    print (\"Recall: \" , TP/(TP+FN))\n",
    "    print (\"\\n\")\n",
    "    TrueP.append(TP)\n",
    "    FalseN.append(FN)\n",
    "    FalseP.append(FP)\n",
    "    TrueN.append(TN)\n",
    "    pre += (TP/(TP+FP))\n",
    "    rec += TP/(TP+FN)\n",
    "\n",
    "print (\"pre: \", pre/3)\n",
    "print (\"rec:\", rec/3)\n",
    "    \n",
    "# Average confusion matrix for all classes\n",
    "TP = np.sum(TrueP)\n",
    "FN = np.sum(FalseN)\n",
    "FP = np.sum(FalseP)\n",
    "TN = np.sum(TrueN)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.82352941 0.84444444 0.86956522]\n",
      "\n",
      "\n",
      "0.8458463578668182\n"
     ]
    }
   ],
   "source": [
    "# calculate f-score for each category\n",
    "f1 = f1_score(y_testArray,pred, average=None)\n",
    "\n",
    "print (f1)\n",
    "print (\"\\n\")\n",
    "print (np.sum(f1)/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-score\n",
      "-----\n",
      "Weighted:  0.8438761011651037\n",
      "Micro:  0.8431372549019607\n",
      "Macro:  0.8458463578668182\n"
     ]
    }
   ],
   "source": [
    "# calculate f-score for all \n",
    "print (\"F-score\\n-----\")\n",
    "print (\"Weighted: \", f1_score(y_testArray,pred, average='weighted'))\n",
    "print (\"Micro: \", f1_score(y_testArray,pred, average='micro'))\n",
    "print (\"Macro: \", f1_score(y_testArray,pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Homicide       0.82      0.82      0.82        17\n",
      "  Parricide       0.79      0.90      0.84        21\n",
      "     Murder       1.00      0.77      0.87        13\n",
      "\n",
      "avg / total       0.86      0.84      0.84        51\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = ['Homicide', 'Parricide', 'Murder']\n",
    "print(classification_report(y_testArray, pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classify(facts='Burlington 12-year-old Accused of killing two parents and wounding two siblings. Charged as a juvenile.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NEW DATA CHAROT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['parricide'], dtype='<U9')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words1 = \"Jose killed his wife\".lower()\n",
    "toks = w2v_tokenize_text(words1)\n",
    "word_average = word_averaging(model,toks)\n",
    "clf.predict([word_average])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('its', 0.40056002140045166),\n",
       " ('such', 0.30158936977386475),\n",
       " ('entry', 0.2709656357765198),\n",
       " ('particular', 0.26304927468299866),\n",
       " ('subsequent', 0.2630005180835724),\n",
       " ('prison', 0.26007795333862305),\n",
       " ('this', 0.25675860047340393),\n",
       " ('assailant', 0.25575560331344604),\n",
       " ('florencios', 0.25463926792144775),\n",
       " ('subject', 0.25001856684684753)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word1 = \"the\"\n",
    "model.wv.most_similar (positive=word1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save to pickle\n",
    "import pickle\n",
    "\n",
    "with open('categorizer_orig.pkl', 'wb') as f:\n",
    "    pickle.dump(clf, f)\n",
    "    \n",
    "with open('tokenizer.pkl', 'wb') as f:\n",
    "    pickle.dump(w2v_tokenize_text, f)\n",
    "    \n",
    "with open('word_average.pkl', 'wb') as f:\n",
    "    pickle.dump(word_averaging, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['parricide'], dtype='<U9')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words1 = \"He killed his wife\".lower()\n",
    "toks = w2v_tokenize_text(words1)\n",
    "word_average = word_averaging(model,toks)\n",
    "clf.predict([word_average])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
